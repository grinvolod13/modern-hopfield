{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hopfield_modern.hopfield_modern import Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(prediction, data):\n",
    "    t = prediction - data\n",
    "    # print(np.linalg.norm(t))\n",
    "    return  -np.linalg.norm(t)\n",
    "    # return np.sum(np.abs(data))\n",
    "    \n",
    "    \n",
    "def norm2(prediction, data):\n",
    "    t = (prediction - data)\n",
    "    return 1/(np.linalg.norm(t) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(data):\n",
    "    t = np.exp(data - np.max(data))\n",
    "    return t/np.sum(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dir(dataset: list, path: str, label: bool, sort=True):\n",
    "    dataset.sort(key=lambda e: e[\"id\"])\n",
    "    if dataset:\n",
    "        index = dataset[-1][\"id\"]+1\n",
    "    else:\n",
    "        index = 0\n",
    "    fnames = [(path+\"/Red/\"+i[:2]+\"_Red.txt\", path+\"/Green/\"+i[:2]+\"_Green.txt\",path+\"/Blue/\"+i[:2]+\"_Blue.txt\") for i in [i for i in os.walk(path)][1][2]]\n",
    "    for fname in fnames:\n",
    "        person = {\"id\": index}\n",
    "        person[\"label\"] = label\n",
    "        with open(fname[0],\"r\") as rfile, open(fname[1],\"r\") as gfile, open(fname[2],\"r\") as bfile:\n",
    "            person[\"r\"] = [float(i) for i in rfile.readlines()[1:]]\n",
    "            person[\"g\"] = [float(i) for i in gfile.readlines()[1:]]\n",
    "            person[\"b\"] = [float(i) for i in bfile.readlines()[1:]]\n",
    "        \n",
    "        if sort:\n",
    "            person[\"r\"].sort()\n",
    "            person[\"g\"].sort()            \n",
    "            person[\"b\"].sort()\n",
    "        \n",
    "        index+=1\n",
    "        dataset.append(person)\n",
    "        \n",
    "def load_dataset(dataset: list, path: str, pathpos: str, pathneg: str, sort=True):\n",
    "    load_dir(dataset, path+\"/\"+pathpos, True, sort=sort)\n",
    "    load_dir(dataset, path+\"/\"+pathneg, False, sort=sort)    \n",
    "        \n",
    "        \n",
    "# def get_filter(dataset: list, filter: str):\n",
    "#     if filter!=\"r\" and filter!=\"g\" and filter!=\"b\":\n",
    "#         raise ValueError('Wrong filter: must be \"r\", \"g\", \"b\"')\n",
    "#     new_dataset = []\n",
    "#     for person in dataset:\n",
    "#         new_dataset.append({\"id\": person[\"id\"], \"label\": person[\"label\"], \"data\": person[filter]})\n",
    "    \n",
    "#     return new_dataset\n",
    "\n",
    "def show_plot_by_filter(dataset: list, filter: str):\n",
    "    plt.clf()\n",
    "    if filter!=\"r\" and filter!=\"g\" and filter!=\"b\":\n",
    "        raise ValueError('Wrong filter: must be \"r\", \"g\", \"b\"')\n",
    "    for i in np.arange(0,len(dataset), 1):\n",
    "        color=\"green\"\n",
    "        if dataset[i][\"label\"]:\n",
    "            color=\"red\"\n",
    "        for j in dataset[i][filter]:\n",
    "            plt.plot(i,j, \"o\", markersize=0.5, color=color)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def binarize_person(person: dict, precision=1e-3, up=1.8, down=0.2, radius=0, flatten=True, filters=3):\n",
    "    person_data = np.zeros((3, int((up-down)//precision)+1), np.float32)[0:filters]\n",
    "    \n",
    "    dots  = (\n",
    "        ((np.array(person[\"r\"]).clip(down, up)-down)//precision).astype(np.uint32),\n",
    "        ((np.array(person[\"g\"]).clip(down, up)-down)//precision).astype(np.uint32),\n",
    "        ((np.array(person[\"b\"]).clip(down, up)-down)//precision).astype(np.uint32))[0:filters]\n",
    "\n",
    "    \n",
    "    for color_index in range(filters):\n",
    "        for dot in dots[color_index]:\n",
    "            person_data[color_index][max(0, dot-radius) : min(dot+radius+1, person_data.shape[1])].fill(1)\n",
    "    \n",
    "    if flatten:\n",
    "        return {\"id\": person[\"id\"], \"label\": person[\"label\"], \"data\": person_data.flatten()}\n",
    "    else:\n",
    "        return {\"id\": person[\"id\"], \"label\": person[\"label\"], \"data\": person_data}\n",
    "\n",
    "def binarize_person_by_filter(person: dict, precision=1e-3, up=1.8, down=0.2, radius=0, flatten=True, filter='g'):\n",
    "    person_data = np.zeros((int((up-down)//precision)+1), np.float32)\n",
    "    \n",
    "    dots  = ((np.array(person[filter]).clip(down, up)-down)//precision).astype(np.uint32)\n",
    "\n",
    "    \n",
    "    for dot in dots:\n",
    "        person_data[max(0, dot-radius) : min(dot+radius+1, person_data.shape[0])].fill(1)\n",
    "    \n",
    "    if flatten:\n",
    "        return {\"id\": person[\"id\"], \"label\": person[\"label\"], \"data\": person_data.flatten()}\n",
    "    else:\n",
    "        return {\"id\": person[\"id\"], \"label\": person[\"label\"], \"data\": person_data}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_plot_avg_by_filter(dataset: list, filter: str):\n",
    "    plt.clf()\n",
    "    if filter!=\"r\" and filter!=\"g\" and filter!=\"b\":\n",
    "        raise ValueError('Wrong filter: must be \"r\", \"g\", \"b\"')\n",
    "    for person in dataset:\n",
    "        \n",
    "        if person[\"label\"]:\n",
    "            color=\"red\"\n",
    "            x = 0\n",
    "        else:\n",
    "            color=\"green\"\n",
    "            x = 1\n",
    "             \n",
    "        for y in person[filter]:\n",
    "            plt.plot(x,y, \"o\", markersize=0.5, color=color)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_score_i(dataset: np.ndarray, X: np.ndarray, i: int, score_fn: Callable):\n",
    "    # if i==0:\n",
    "    #     max_i = 1\n",
    "    # else:\n",
    "    #     max_i = 0\n",
    "    max_i = 0\n",
    "    # print(f\"len {len(dataset)}\")\n",
    "    # for j in (k for k in range(len(dataset)) if k!=i):\n",
    "    for j in range(len(dataset)):\n",
    "        if score_fn(X,dataset[max_i]) <= score_fn(X,dataset[j]):\n",
    "            max_i = j\n",
    "            \n",
    "    return max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(dataset, channel):\n",
    "    mx = max([len(p[channel]) for p in dataset])\n",
    "    out = np.zeros(mx+1, dtype=int)\n",
    "    \n",
    "    for p in dataset:\n",
    "        out[:len(p[channel])] += 1\n",
    "        \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_of_min_dims(dataset, channel, ndims):\n",
    "    mask = np.zeros(len(dataset), dtype=bool)\n",
    "    for index in range(len(dataset)):\n",
    "        if len(dataset[index][channel])>=ndims:\n",
    "            mask[index] = True\n",
    "    \n",
    "    return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "dataset_full = []\n",
    "load_dataset(dataset_full, \"C:/Users/User/Desktop/Data/Data\", \"BC\", \"Control\", sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random.shuffle(dataset_full)\n",
    "\n",
    "\n",
    "# train, test = dataset_full[:int(len(dataset_full)*train_ratio)], dataset_full[int(len(dataset_full)*train_ratio):]\n",
    "# print(f\"Train set: {len(train)}\")\n",
    "# print(f\"Test set: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#N = 40 # const in test 28\n",
    "channel = 'b'\n",
    "num_of_dims = 23 #55\n",
    "# assert np.sum(get_mask_of_min_dims(train, channel, num_of_dims)) == len(train)\n",
    "# assert np.sum(get_mask_of_min_dims(test, channel, num_of_dims)) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dims = np.array([{'data': random.sample(person[channel], num_of_dims),\n",
    "                                'label': person['label'],\n",
    "                                'id': person['id']\n",
    "                                } for person in dataset_full])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e248b95d2f2481c950d52dc2106bb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 230 is different from 96)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m memory \u001b[38;5;241m=\u001b[39m _images[_mask]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     45\u001b[0m model \u001b[38;5;241m=\u001b[39m Hopfield(memory)\n\u001b[1;32m---> 46\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m max_i \u001b[38;5;241m=\u001b[39m max_score_i(dataset\u001b[38;5;241m=\u001b[39m_images, X\u001b[38;5;241m=\u001b[39mout, i\u001b[38;5;241m=\u001b[39mi, score_fn\u001b[38;5;241m=\u001b[39mnorm)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_dim[max_i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mdataset_full[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\Desktop\\modern-hopfield\\hopfield_modern\\hopfield_modern.py:15\u001b[0m, in \u001b[0;36mHopfield.run\u001b[1;34m(self, E, b)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, E: np\u001b[38;5;241m.\u001b[39mndarray, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\modern-hopfield\\hopfield_modern\\hopfield_modern.py:8\u001b[0m, in \u001b[0;36mHopfield._step\u001b[1;34m(self, E, b)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, E: np\u001b[38;5;241m.\u001b[39mndarray, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     t \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m)\n\u001b[0;32m      9\u001b[0m     t \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(t)\n\u001b[0;32m     10\u001b[0m     t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(t)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 230 is different from 96)"
     ]
    }
   ],
   "source": [
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "image_scaling_test = [10]\n",
    "tests_per_generation = 100\n",
    "\n",
    "\n",
    "\n",
    "for image_scaling in (image_scaling_test):\n",
    "    print(image_scaling)\n",
    "    one_scale = []\n",
    "    \n",
    "    \n",
    "    for test_iteration in tqdm_notebook(range(tests_per_generation)):\n",
    "        one_test = []\n",
    "        \n",
    "        dataset_dim = np.array([{'data': random.sample(person[channel], num_of_dims),\n",
    "                                'label': person['label'],\n",
    "                                'id': person['id']\n",
    "                                } for person in dataset_full])\n",
    "\n",
    "        _images = np.array([i['data'] for i in dataset_dim])\n",
    "        _images = np.array([np.concatenate([i]*image_scaling) for i in _images])\n",
    "\n",
    "\n",
    "        for p in _images:\n",
    "            p.sort()\n",
    "            \n",
    "        _images -= _images.min()\n",
    "        _images /= _images.max()\n",
    "        # dataset_color = softmax(dataset_color) # not!!!\n",
    "\n",
    "        _images = _images*2-1\n",
    "        \n",
    "        \n",
    "\n",
    "        for i in range(len(dataset_full)):\n",
    "            \n",
    "            _mask = np.ones(len(_images), dtype=bool)\n",
    "            _mask[i] = False\n",
    "\n",
    "            _X = _images[i].copy()\n",
    "            memory = _images[_mask].copy()\n",
    "            \n",
    "            model = Hopfield(memory)\n",
    "            out = model.run(_X, 5)\n",
    "            max_i = max_score_i(dataset=_images, X=out, i=i, score_fn=norm)\n",
    "            \n",
    "            \n",
    "            if dataset_dim[max_i][\"label\"]==dataset_full[i][\"label\"]:\n",
    "                one_test.append(1)\n",
    "            else:\n",
    "                one_test.append(0)\n",
    "    \n",
    "        one_scale.append(np.average(one_test))\n",
    "    result.append((image_scaling, _images.shape[0]/_images.shape[1], np.average(one_scale)))\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame(result)\n",
    "dataframe.to_csv(\"results.csv\", index=False)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
